[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Natural Language Processing - praktische Übungen",
    "section": "",
    "text": "Hier finden Sie einfache Übungen zum Thema Natural Language Processing - ein großes Wort für eine einfache Idee: Text in seine Bestandteile zu zerlegen und quantitative nutzbar zu machen.\n\n\n\n\nJane Austen\n\n\n\nIn diesen Übungen konzentrieren wir uns im ersten Schritt auf die sehr bekannten Romane von Jane Austen:\n\nsensesensibility: Sense and Sensibility (deutsch: Verstand und Gefühl), veröffentlicht 1811\nprideprejudice: Pride and Prejudice (deutsch: Stolz und Vorurteil), veröffentlicht 1813\nmansfieldpark: Mansfield Park, veröffentlicht 1814\nemma: Emma, veröffentlicht 1815\nnorthangerabbey: Northanger Abbey (deutsch: Die Abtei von Northanger), posthum veröffentlicht 1818\npersuasion: Persuasion (auch: Anne Elliot), posthum veröffentlicht 1818\n\nWir werden uns aus zwei Gründen die Romane in englischer Sprache ansehen:\n\nKI Modelle basieren zum größten Teil auf englischer Sprache - das macht es einfacher\nWir müssen die Romane selber gar nicht verstehen!\n\nVielen Dank an Project Gutenberg das digitale Kopien von über \\(70.000\\) Büchern in digitaler Form zur Verfügung stellt."
  },
  {
    "objectID": "get_started.html",
    "href": "get_started.html",
    "title": "Anfänge in NLP",
    "section": "",
    "text": "Die Bücher - Rohdaten\nIm ersten Schritt lesen wir die Daten ein. Hierzu benutzen wir die Statistikumgebung R, sie müssen aber nicht viel über Programmieren wissen um die Befehle auszuführen. Wir müssen die Daten leider ein wenig beschränken, da wir sonst nicht mehr alles in einer Tabelle darstellen können.\n\n\n\n\n\n\n\n\nVorbereitung der Daten\nUnten werden Sie zum ersten Mal selber tätig. Vieles mag im ersten Schritt kryptisch aussehen, aber am Ende des Tages sind es recht einfache Übungen: Mit dem Befehl austen_books() holen wir die Rohdaten in unsere Programmierumgebung. Für die weitere Analyse der Daten gruppieren wir die Daten nach Buch (group_by(book)). Der mutate() Befehl ist schon komplizierter, aber eigentlich bauen wir uns nur eine Variable, die sagt in welcher Zeile im Buch der Text steht (linenumber = row_number()). Im letzten Schritt zählen wir Kapitel. Zugegebenermaßen sieht regex(\"^chapter [\\\\divxlc]\" furchteinflößend aus. Der Befehl ist eine regular expression und sucht im Text nach dem Wort chapter. cumsum() ist die kumulierte Summe der Kapitel. Das alles speichern wir in original_books, mit datatable() haben wir die Möglichkeit, die Daten interaktiv zu begutachten.\n\n\n\n\n\n\n\n\n\n\nTokenisierung\nIm nächsten Schritt werden die Wörter tokenisiert. Tokeninsierung bedeutet am Ende nichts anderes, als das ein langer Satz oder Text in seine Bestandteile zerlegt wird, um diesen dann für den Computer nutzbar und “verstehbar” zu machen. Der Satz: “Ich liebe Eis!” würde in einer Tokenisierung in die Tokens “Ich”, “liebe”, “Eis” und “!” zerlegt werden. Ein einzelener Satz",
    "crumbs": [
      "Anfänge in NLP"
    ]
  }
]